{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Train Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Using your baseline model from yesterday, hyperparameter tune it and report on your highest validation accuracy. Your singular goal today is to achieve the highest accuracy possible.\n",
    "\n",
    "*Don't forgot to switch to GPU on Colab!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJ2b3wk62Ud"
   },
   "source": [
    "### Hyperparameters to Tune\n",
    "\n",
    "At a minimum, tune each of these hyperparameters using any strategy we discussed during lecture today: \n",
    "- Optimizer\n",
    "- Learning Rate\n",
    "- Activiation Function\n",
    "  - At least 1 subparameter within the Relu activation function\n",
    "- Number of Neurons in Hidden Layers\n",
    "- Number of Hidden Layers\n",
    "- Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USXjs7Hk71Hy"
   },
   "outputs": [],
   "source": [
    "# Your Code Starts Here\n",
    "def load_quickdraw10(path):\n",
    "  data = np.load(path)\n",
    "  X = data['arr_0']\n",
    "  y = data['arr_1']\n",
    "  X, y = shuffle(X, y)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                      random_state=42)\n",
    "  \n",
    "  return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_quickdraw10('../quickdraw10.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Nadam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(units=32):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, input_dim=784, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "417/417 [==============================] - 0s 745us/step - loss: 6.2975 - accuracy: 0.3955\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 0s 737us/step - loss: 1.5347 - accuracy: 0.5012\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 0s 751us/step - loss: 1.2615 - accuracy: 0.5996\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 0s 778us/step - loss: 1.0801 - accuracy: 0.6540\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 0s 746us/step - loss: 0.9770 - accuracy: 0.6859\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 0s 750us/step - loss: 0.8914 - accuracy: 0.7117\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 0s 736us/step - loss: 0.8470 - accuracy: 0.7246\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 0s 748us/step - loss: 0.8044 - accuracy: 0.7354\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 0s 746us/step - loss: 0.7743 - accuracy: 0.7467\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 0s 754us/step - loss: 0.7396 - accuracy: 0.7612\n",
      "Epoch 11/20\n",
      "417/417 [==============================] - 0s 748us/step - loss: 0.7042 - accuracy: 0.7744\n",
      "Epoch 12/20\n",
      "417/417 [==============================] - 0s 755us/step - loss: 0.6814 - accuracy: 0.7928\n",
      "Epoch 13/20\n",
      "417/417 [==============================] - 0s 754us/step - loss: 0.6700 - accuracy: 0.7990\n",
      "Epoch 14/20\n",
      "417/417 [==============================] - 0s 742us/step - loss: 0.6608 - accuracy: 0.8022\n",
      "Epoch 15/20\n",
      "417/417 [==============================] - 0s 756us/step - loss: 0.6504 - accuracy: 0.8064\n",
      "Epoch 16/20\n",
      "417/417 [==============================] - 0s 747us/step - loss: 0.6436 - accuracy: 0.8085\n",
      "Epoch 17/20\n",
      "417/417 [==============================] - 0s 796us/step - loss: 0.6365 - accuracy: 0.8095\n",
      "Epoch 18/20\n",
      "417/417 [==============================] - 0s 751us/step - loss: 0.6306 - accuracy: 0.8116\n",
      "Epoch 19/20\n",
      "417/417 [==============================] - 0s 755us/step - loss: 0.6292 - accuracy: 0.8138\n",
      "Epoch 20/20\n",
      "417/417 [==============================] - 0s 741us/step - loss: 0.6234 - accuracy: 0.8154\n",
      "Best: 0.7867500066757203 using {'batch_size': 192, 'epochs': 20, 'units': 64}\n",
      "Means: 0.5569124937057495, Stdev: 0.050250775817415536 with: {'batch_size': 8, 'epochs': 20, 'units': 32}\n",
      "Means: 0.6270749926567077, Stdev: 0.031866049940757674 with: {'batch_size': 8, 'epochs': 20, 'units': 64}\n",
      "Means: 0.6862499833106994, Stdev: 0.04244742004102628 with: {'batch_size': 32, 'epochs': 20, 'units': 32}\n",
      "Means: 0.753737497329712, Stdev: 0.011045472089300686 with: {'batch_size': 32, 'epochs': 20, 'units': 64}\n",
      "Means: 0.7045750021934509, Stdev: 0.03453312100916447 with: {'batch_size': 64, 'epochs': 20, 'units': 32}\n",
      "Means: 0.7626999974250793, Stdev: 0.005991704346101966 with: {'batch_size': 64, 'epochs': 20, 'units': 64}\n",
      "Means: 0.7163874983787537, Stdev: 0.00901746429589977 with: {'batch_size': 192, 'epochs': 20, 'units': 32}\n",
      "Means: 0.7867500066757203, Stdev: 0.002571770840465654 with: {'batch_size': 192, 'epochs': 20, 'units': 64}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [8, 32,64,192],\n",
    "              'epochs': [20],\n",
    "              'units':[32, 64]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16,32]))\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.RealInterval(0.001,.01))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'Nadam']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "      hparams=[HP_NUM_UNITS, HP_LEARNING_RATE, HP_OPTIMIZER],\n",
    "      metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation='relu'),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    opt_name = hparams[HP_OPTIMIZER]\n",
    "    lr = hparams[HP_LEARNING_RATE]\n",
    "    \n",
    "    if opt_name == 'adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif opt_name == 'Nadam':\n",
    "        opt = tf.keras.optimizers.Nadam(learning_rate=lr)\n",
    "    else:\n",
    "        raise ValueError(\"unexpected optimizer name: {}\".format(opt_name))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=30)\n",
    "    _, accuracy = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Trial: run 0\n",
      "{'num_units': 16, 'learning_rate': 0.001, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "2500/2500 [==============================] - 1s 424us/step - loss: 2.6610 - accuracy: 0.2059\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 1s 423us/step - loss: 1.8940 - accuracy: 0.2855\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 1s 430us/step - loss: 1.6893 - accuracy: 0.3707\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 1s 431us/step - loss: 1.3379 - accuracy: 0.5089\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 1s 429us/step - loss: 1.2490 - accuracy: 0.5485\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 1s 438us/step - loss: 1.2183 - accuracy: 0.5614\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 1s 436us/step - loss: 1.2026 - accuracy: 0.5643\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 1s 432us/step - loss: 1.1926 - accuracy: 0.5659\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 1s 428us/step - loss: 1.1851 - accuracy: 0.5673\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 1s 437us/step - loss: 1.1795 - accuracy: 0.5749\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 1s 440us/step - loss: 1.1734 - accuracy: 0.5757\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 1s 441us/step - loss: 1.1705 - accuracy: 0.5741\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 1s 439us/step - loss: 1.1677 - accuracy: 0.5778\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 1s 437us/step - loss: 1.1655 - accuracy: 0.5817\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 1s 434us/step - loss: 1.1601 - accuracy: 0.5852\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 1s 431us/step - loss: 1.1597 - accuracy: 0.5889\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 1s 427us/step - loss: 1.1579 - accuracy: 0.5897\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 1s 429us/step - loss: 1.1554 - accuracy: 0.5965\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - 1s 431us/step - loss: 1.1517 - accuracy: 0.6006\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 1s 434us/step - loss: 1.1517 - accuracy: 0.6021\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 1s 432us/step - loss: 1.1493 - accuracy: 0.6019\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 1s 436us/step - loss: 1.1482 - accuracy: 0.6042\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 1s 421us/step - loss: 1.1454 - accuracy: 0.6061\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 1s 425us/step - loss: 1.1452 - accuracy: 0.6050\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 1s 432us/step - loss: 1.1434 - accuracy: 0.6067\n",
      "Epoch 26/30\n",
      "2500/2500 [==============================] - 1s 435us/step - loss: 1.1423 - accuracy: 0.6058\n",
      "Epoch 27/30\n",
      "2500/2500 [==============================] - 1s 435us/step - loss: 1.1428 - accuracy: 0.6048\n",
      "Epoch 28/30\n",
      "2500/2500 [==============================] - 1s 437us/step - loss: 1.1412 - accuracy: 0.6059\n",
      "Epoch 29/30\n",
      "2500/2500 [==============================] - 1s 447us/step - loss: 1.1395 - accuracy: 0.6060\n",
      "Epoch 30/30\n",
      "2500/2500 [==============================] - 1s 444us/step - loss: 1.1398 - accuracy: 0.6057\n",
      "625/625 [==============================] - 0s 333us/step - loss: 1.1673 - accuracy: 0.6058\n",
      "--- Starting Trial: run 1\n",
      "{'num_units': 16, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "2500/2500 [==============================] - 1s 431us/step - loss: 2.6068 - accuracy: 0.1610\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 1s 430us/step - loss: 1.8609 - accuracy: 0.3004\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 1s 425us/step - loss: 1.6158 - accuracy: 0.3925\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 1s 422us/step - loss: 1.4857 - accuracy: 0.4361\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 1s 422us/step - loss: 1.4263 - accuracy: 0.4496\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 1s 422us/step - loss: 1.4015 - accuracy: 0.4544\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 1s 422us/step - loss: 1.3912 - accuracy: 0.4601\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 1s 422us/step - loss: 1.3877 - accuracy: 0.4592\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 1s 422us/step - loss: 1.3880 - accuracy: 0.4617\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 1s 424us/step - loss: 1.3850 - accuracy: 0.4612\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 1s 422us/step - loss: 1.3796 - accuracy: 0.4632\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 1s 421us/step - loss: 1.3750 - accuracy: 0.4629\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 1s 423us/step - loss: 1.3822 - accuracy: 0.4622\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 1s 425us/step - loss: 1.3820 - accuracy: 0.4639\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 1s 424us/step - loss: 1.3766 - accuracy: 0.4659\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 1s 425us/step - loss: 1.3664 - accuracy: 0.4735\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 1s 425us/step - loss: 1.3587 - accuracy: 0.4763\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 1s 425us/step - loss: 1.3478 - accuracy: 0.4812\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - 1s 439us/step - loss: 1.3334 - accuracy: 0.4873\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 1s 436us/step - loss: 1.3195 - accuracy: 0.4953\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 1s 434us/step - loss: 1.3134 - accuracy: 0.4982\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 1s 441us/step - loss: 1.3023 - accuracy: 0.5071\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 1s 442us/step - loss: 1.2803 - accuracy: 0.5195\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 1s 438us/step - loss: 1.2531 - accuracy: 0.5362\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 1s 438us/step - loss: 1.2431 - accuracy: 0.5488\n",
      "Epoch 26/30\n",
      "2500/2500 [==============================] - 1s 438us/step - loss: 1.2319 - accuracy: 0.5567\n",
      "Epoch 27/30\n",
      "2500/2500 [==============================] - 1s 439us/step - loss: 1.2169 - accuracy: 0.5648\n",
      "Epoch 28/30\n",
      "2500/2500 [==============================] - 1s 443us/step - loss: 1.2095 - accuracy: 0.5696\n",
      "Epoch 29/30\n",
      "2500/2500 [==============================] - 1s 436us/step - loss: 1.2093 - accuracy: 0.5694\n",
      "Epoch 30/30\n",
      "2500/2500 [==============================] - 1s 432us/step - loss: 1.2020 - accuracy: 0.5718\n",
      "625/625 [==============================] - 0s 338us/step - loss: 1.2504 - accuracy: 0.5774\n",
      "--- Starting Trial: run 2\n",
      "{'num_units': 16, 'learning_rate': 0.01, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "2500/2500 [==============================] - 1s 443us/step - loss: 2.4506 - accuracy: 0.1004\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 1s 437us/step - loss: 2.3039 - accuracy: 0.0999\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 1s 435us/step - loss: 2.3039 - accuracy: 0.1011\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 1s 437us/step - loss: 2.3040 - accuracy: 0.0992\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 1s 433us/step - loss: 2.3039 - accuracy: 0.1003\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 1s 436us/step - loss: 2.3041 - accuracy: 0.0975\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 1s 436us/step - loss: 2.3039 - accuracy: 0.1004\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 1s 433us/step - loss: 2.3039 - accuracy: 0.0988\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 1s 438us/step - loss: 2.3039 - accuracy: 0.0992\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 1s 438us/step - loss: 2.3040 - accuracy: 0.0991\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 1s 438us/step - loss: 2.3040 - accuracy: 0.1006\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 1s 434us/step - loss: 2.3038 - accuracy: 0.1009\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 1s 435us/step - loss: 2.3040 - accuracy: 0.0982\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 1s 433us/step - loss: 2.3039 - accuracy: 0.1007\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 1s 430us/step - loss: 2.3039 - accuracy: 0.0995\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 1s 420us/step - loss: 2.3039 - accuracy: 0.1004\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 1s 425us/step - loss: 2.3039 - accuracy: 0.1006\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 1s 419us/step - loss: 2.3040 - accuracy: 0.0982\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - 1s 421us/step - loss: 2.3038 - accuracy: 0.1004\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 1s 421us/step - loss: 2.3040 - accuracy: 0.0996\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 1s 426us/step - loss: 2.3039 - accuracy: 0.1007\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 1s 444us/step - loss: 2.3039 - accuracy: 0.0979\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 1s 432us/step - loss: 2.3040 - accuracy: 0.0978\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 1s 447us/step - loss: 2.3039 - accuracy: 0.10070s - loss: 2.3039 - accuracy: 0.10\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 1s 480us/step - loss: 2.3037 - accuracy: 0.1014\n",
      "Epoch 26/30\n",
      "2500/2500 [==============================] - 1s 484us/step - loss: 2.3040 - accuracy: 0.0982\n",
      "Epoch 27/30\n",
      "2500/2500 [==============================] - 1s 486us/step - loss: 2.3039 - accuracy: 0.0970\n",
      "Epoch 28/30\n",
      "2500/2500 [==============================] - 1s 501us/step - loss: 2.3038 - accuracy: 0.0999\n",
      "Epoch 29/30\n",
      "2500/2500 [==============================] - 1s 435us/step - loss: 2.3038 - accuracy: 0.0988\n",
      "Epoch 30/30\n",
      "2500/2500 [==============================] - 1s 430us/step - loss: 2.3039 - accuracy: 0.0998\n",
      "625/625 [==============================] - 0s 348us/step - loss: 2.3052 - accuracy: 0.1014\n",
      "--- Starting Trial: run 3\n",
      "{'num_units': 16, 'learning_rate': 0.01, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "2500/2500 [==============================] - 1s 433us/step - loss: 2.4240 - accuracy: 0.1016\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 1s 431us/step - loss: 2.3037 - accuracy: 0.0993\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 1s 434us/step - loss: 2.3039 - accuracy: 0.1000\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 1s 429us/step - loss: 2.3039 - accuracy: 0.1000\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 1s 428us/step - loss: 2.3041 - accuracy: 0.1000\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 1s 434us/step - loss: 2.3038 - accuracy: 0.0989\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 1s 430us/step - loss: 2.3041 - accuracy: 0.0982\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 1s 432us/step - loss: 2.3039 - accuracy: 0.0993\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 1s 430us/step - loss: 2.3041 - accuracy: 0.0999\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 1s 430us/step - loss: 2.3039 - accuracy: 0.0993\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 1s 438us/step - loss: 2.3040 - accuracy: 0.0993\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 1s 440us/step - loss: 2.3040 - accuracy: 0.0984\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 1s 437us/step - loss: 2.3041 - accuracy: 0.0988\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 1s 435us/step - loss: 2.3039 - accuracy: 0.0993\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 1s 477us/step - loss: 2.3039 - accuracy: 0.1008\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 1s 444us/step - loss: 2.3041 - accuracy: 0.0986\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 1s 443us/step - loss: 2.3039 - accuracy: 0.1014\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 1s 477us/step - loss: 2.3039 - accuracy: 0.0997\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - 1s 444us/step - loss: 2.3038 - accuracy: 0.1002\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 1s 450us/step - loss: 2.3040 - accuracy: 0.1004\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 1s 439us/step - loss: 2.3041 - accuracy: 0.0986\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 1s 456us/step - loss: 2.3039 - accuracy: 0.0999\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 1s 436us/step - loss: 2.3041 - accuracy: 0.0991\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 1s 438us/step - loss: 2.3040 - accuracy: 0.0998\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 1s 447us/step - loss: 2.3040 - accuracy: 0.0995\n",
      "Epoch 26/30\n",
      "2500/2500 [==============================] - 1s 452us/step - loss: 2.3038 - accuracy: 0.1012\n",
      "Epoch 27/30\n",
      "2500/2500 [==============================] - 1s 464us/step - loss: 2.3040 - accuracy: 0.0981\n",
      "Epoch 28/30\n",
      "2500/2500 [==============================] - 1s 452us/step - loss: 2.3039 - accuracy: 0.0995\n",
      "Epoch 29/30\n",
      "2500/2500 [==============================] - 1s 457us/step - loss: 2.3039 - accuracy: 0.1007\n",
      "Epoch 30/30\n",
      "2500/2500 [==============================] - 1s 456us/step - loss: 2.3039 - accuracy: 0.1015\n",
      "625/625 [==============================] - 0s 349us/step - loss: 2.3038 - accuracy: 0.0998\n",
      "--- Starting Trial: run 4\n",
      "{'num_units': 32, 'learning_rate': 0.001, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "   1/2500 [..............................] - ETA: 0s - loss: 153.4784 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "2500/2500 [==============================] - 1s 507us/step - loss: 2.5746 - accuracy: 0.32620s - loss: 2.6147 - accuracy: 0.\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 1s 487us/step - loss: 1.4954 - accuracy: 0.4700\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 1s 492us/step - loss: 1.2906 - accuracy: 0.5400\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 1s 489us/step - loss: 1.1348 - accuracy: 0.6133\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 1s 496us/step - loss: 1.0309 - accuracy: 0.6599\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 1s 478us/step - loss: 0.9813 - accuracy: 0.6810\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 1s 492us/step - loss: 0.9399 - accuracy: 0.7037\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 1s 478us/step - loss: 0.9180 - accuracy: 0.7098\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 1s 458us/step - loss: 0.9050 - accuracy: 0.7135\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 1s 459us/step - loss: 0.8969 - accuracy: 0.7158\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 1s 462us/step - loss: 0.8972 - accuracy: 0.7177\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 1s 464us/step - loss: 0.8864 - accuracy: 0.7197\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 1s 457us/step - loss: 0.8803 - accuracy: 0.7226\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 1s 455us/step - loss: 0.8757 - accuracy: 0.7242\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 1s 460us/step - loss: 0.8740 - accuracy: 0.7228\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 1s 458us/step - loss: 0.8717 - accuracy: 0.7266\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 1s 458us/step - loss: 0.8694 - accuracy: 0.7279\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 1s 454us/step - loss: 0.8688 - accuracy: 0.7283\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - 1s 462us/step - loss: 0.8645 - accuracy: 0.7301\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 1s 460us/step - loss: 0.8617 - accuracy: 0.7288\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 1s 463us/step - loss: 0.8608 - accuracy: 0.7291\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 1s 468us/step - loss: 0.8591 - accuracy: 0.7319\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 1s 468us/step - loss: 0.8577 - accuracy: 0.7304\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 1s 471us/step - loss: 0.8574 - accuracy: 0.7322\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 1s 478us/step - loss: 0.8561 - accuracy: 0.7325\n",
      "Epoch 26/30\n",
      "2500/2500 [==============================] - 1s 472us/step - loss: 0.8543 - accuracy: 0.7332\n",
      "Epoch 27/30\n",
      "2500/2500 [==============================] - 1s 468us/step - loss: 0.8540 - accuracy: 0.7327\n",
      "Epoch 28/30\n",
      "2500/2500 [==============================] - 1s 470us/step - loss: 0.8507 - accuracy: 0.7327\n",
      "Epoch 29/30\n",
      "2500/2500 [==============================] - 1s 476us/step - loss: 0.8523 - accuracy: 0.7346\n",
      "Epoch 30/30\n",
      "2500/2500 [==============================] - 1s 476us/step - loss: 0.8514 - accuracy: 0.7345\n",
      "625/625 [==============================] - 0s 352us/step - loss: 0.9360 - accuracy: 0.7122\n",
      "--- Starting Trial: run 5\n",
      "{'num_units': 32, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "2500/2500 [==============================] - 1s 469us/step - loss: 2.5208 - accuracy: 0.3488\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 1s 474us/step - loss: 1.4892 - accuracy: 0.4695\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 1s 475us/step - loss: 1.2674 - accuracy: 0.5448\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 1s 474us/step - loss: 1.1547 - accuracy: 0.5945\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 1s 471us/step - loss: 1.0853 - accuracy: 0.6383\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 1s 468us/step - loss: 1.0390 - accuracy: 0.6641\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 1s 480us/step - loss: 1.0078 - accuracy: 0.6857\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 1s 471us/step - loss: 0.9771 - accuracy: 0.7011\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 1s 467us/step - loss: 0.9499 - accuracy: 0.7129\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 1s 468us/step - loss: 0.9419 - accuracy: 0.7158\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 1s 474us/step - loss: 0.9304 - accuracy: 0.7179\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 1s 470us/step - loss: 0.9270 - accuracy: 0.7209\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 1s 468us/step - loss: 0.9177 - accuracy: 0.7258\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 1s 469us/step - loss: 0.9144 - accuracy: 0.7278\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 1s 476us/step - loss: 0.9045 - accuracy: 0.7302\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 1s 470us/step - loss: 0.9026 - accuracy: 0.7302\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 1s 472us/step - loss: 0.8977 - accuracy: 0.7318\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 1s 475us/step - loss: 0.8973 - accuracy: 0.7339\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - 1s 477us/step - loss: 0.8881 - accuracy: 0.7355\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 1s 473us/step - loss: 0.8850 - accuracy: 0.7367\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 1s 471us/step - loss: 0.8737 - accuracy: 0.7441\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 1s 471us/step - loss: 0.8675 - accuracy: 0.7468\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 1s 476us/step - loss: 0.8593 - accuracy: 0.7488\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 1s 478us/step - loss: 0.8549 - accuracy: 0.7497\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 1s 479us/step - loss: 0.8502 - accuracy: 0.7520\n",
      "Epoch 26/30\n",
      "2500/2500 [==============================] - 1s 474us/step - loss: 0.8475 - accuracy: 0.7542\n",
      "Epoch 27/30\n",
      "2500/2500 [==============================] - 1s 475us/step - loss: 0.8500 - accuracy: 0.7526\n",
      "Epoch 28/30\n",
      "2500/2500 [==============================] - 1s 470us/step - loss: 0.8420 - accuracy: 0.7548\n",
      "Epoch 29/30\n",
      "2500/2500 [==============================] - 1s 472us/step - loss: 0.8448 - accuracy: 0.7540\n",
      "Epoch 30/30\n",
      "2500/2500 [==============================] - 1s 473us/step - loss: 0.8403 - accuracy: 0.7571\n",
      "625/625 [==============================] - 0s 351us/step - loss: 0.9406 - accuracy: 0.7480\n",
      "--- Starting Trial: run 6\n",
      "{'num_units': 32, 'learning_rate': 0.01, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "2500/2500 [==============================] - 1s 464us/step - loss: 2.6173 - accuracy: 0.1773\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 1s 464us/step - loss: 2.2657 - accuracy: 0.1376\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 1s 451us/step - loss: 2.2911 - accuracy: 0.1258\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 1s 449us/step - loss: 2.3000 - accuracy: 0.1011\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 1s 451us/step - loss: 2.3038 - accuracy: 0.0995\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 1s 458us/step - loss: 2.3039 - accuracy: 0.0989\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 1s 458us/step - loss: 2.3038 - accuracy: 0.0992\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 1s 459us/step - loss: 2.3039 - accuracy: 0.0988\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 1s 454us/step - loss: 2.3040 - accuracy: 0.0988\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 1s 454us/step - loss: 2.3040 - accuracy: 0.0995\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 1s 459us/step - loss: 2.3039 - accuracy: 0.0995\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 1s 454us/step - loss: 2.3088 - accuracy: 0.1010\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 1s 456us/step - loss: 2.3037 - accuracy: 0.0992\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 1s 456us/step - loss: 2.3039 - accuracy: 0.0993\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 1s 450us/step - loss: 2.3039 - accuracy: 0.10040s\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 1s 453us/step - loss: 2.3040 - accuracy: 0.0983\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 1s 451us/step - loss: 2.3038 - accuracy: 0.0993\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 1s 453us/step - loss: 2.3039 - accuracy: 0.0989\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - 1s 455us/step - loss: 2.3039 - accuracy: 0.0988\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 1s 456us/step - loss: 2.3038 - accuracy: 0.1021\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 1s 455us/step - loss: 2.3041 - accuracy: 0.0985\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 1s 459us/step - loss: 2.3039 - accuracy: 0.1002\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 1s 460us/step - loss: 2.3039 - accuracy: 0.1002\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 1s 454us/step - loss: 2.3040 - accuracy: 0.0996\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 1s 456us/step - loss: 2.3039 - accuracy: 0.0989\n",
      "Epoch 26/30\n",
      "2500/2500 [==============================] - 1s 458us/step - loss: 2.3039 - accuracy: 0.0993\n",
      "Epoch 27/30\n",
      "2500/2500 [==============================] - 1s 460us/step - loss: 2.3039 - accuracy: 0.1010\n",
      "Epoch 28/30\n",
      "2500/2500 [==============================] - 1s 463us/step - loss: 2.3040 - accuracy: 0.1002\n",
      "Epoch 29/30\n",
      "2500/2500 [==============================] - 1s 461us/step - loss: 2.3039 - accuracy: 0.0997\n",
      "Epoch 30/30\n",
      "2500/2500 [==============================] - 1s 461us/step - loss: 2.3038 - accuracy: 0.1007\n",
      "625/625 [==============================] - 0s 350us/step - loss: 2.3037 - accuracy: 0.0953\n",
      "--- Starting Trial: run 7\n",
      "{'num_units': 32, 'learning_rate': 0.01, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "2500/2500 [==============================] - 1s 457us/step - loss: 2.5513 - accuracy: 0.1550\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 1s 459us/step - loss: 2.2830 - accuracy: 0.1157\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 1s 468us/step - loss: 2.3045 - accuracy: 0.0989\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 1s 467us/step - loss: 2.3038 - accuracy: 0.1014\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 1s 474us/step - loss: 2.3041 - accuracy: 0.1002\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 1s 466us/step - loss: 2.3040 - accuracy: 0.0991\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 1s 460us/step - loss: 2.3039 - accuracy: 0.0981\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 1s 453us/step - loss: 2.3042 - accuracy: 0.0976\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 1s 461us/step - loss: 2.3039 - accuracy: 0.1004\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 1s 465us/step - loss: 2.3039 - accuracy: 0.1012\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 1s 462us/step - loss: 2.3040 - accuracy: 0.0987\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 1s 459us/step - loss: 2.3038 - accuracy: 0.1023\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 1s 458us/step - loss: 2.3041 - accuracy: 0.0993\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 1s 460us/step - loss: 2.3038 - accuracy: 0.1016\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 1s 464us/step - loss: 2.3040 - accuracy: 0.0997\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 1s 453us/step - loss: 2.3039 - accuracy: 0.1001\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 1s 458us/step - loss: 2.3039 - accuracy: 0.1006\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 1s 459us/step - loss: 2.3038 - accuracy: 0.0998\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - 1s 465us/step - loss: 2.3040 - accuracy: 0.1001\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 1s 461us/step - loss: 2.3039 - accuracy: 0.0989\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 1s 454us/step - loss: 2.3039 - accuracy: 0.1008\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 1s 460us/step - loss: 2.3038 - accuracy: 0.0990\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 1s 466us/step - loss: 2.3040 - accuracy: 0.1002\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 1s 466us/step - loss: 2.3039 - accuracy: 0.0990\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 1s 455us/step - loss: 2.3040 - accuracy: 0.1005\n",
      "Epoch 26/30\n",
      "2500/2500 [==============================] - 1s 452us/step - loss: 2.3040 - accuracy: 0.0999\n",
      "Epoch 27/30\n",
      "2500/2500 [==============================] - 1s 459us/step - loss: 2.3039 - accuracy: 0.0988\n",
      "Epoch 28/30\n",
      "2500/2500 [==============================] - 1s 459us/step - loss: 2.3040 - accuracy: 0.0993\n",
      "Epoch 29/30\n",
      "2500/2500 [==============================] - 1s 459us/step - loss: 2.3040 - accuracy: 0.0999\n",
      "Epoch 30/30\n",
      "2500/2500 [==============================] - 1s 454us/step - loss: 2.3039 - accuracy: 0.1000\n",
      "625/625 [==============================] - 0s 342us/step - loss: 2.3050 - accuracy: 0.0997\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for learning_rate in (HP_LEARNING_RATE.domain.min_value,\n",
    "                          HP_LEARNING_RATE.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_LEARNING_RATE: learning_rate,\n",
    "                HP_OPTIMIZER: optimizer\n",
    "            }\n",
    "            \n",
    "            run_name = \"run {}\".format(session_num)\n",
    "            print( \"--- Starting Trial: {}\".format(run_name))\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5456), started 0:02:23 ago. (Use '!kill 5456' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2b46dc9ce69c54cc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2b46dc9ce69c54cc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKbr1gRg9BXs"
   },
   "source": [
    "### Stretch Goals\n",
    "- Implement Bayesian Hyper-parameter Optimization\n",
    "- Select a new dataset and apply a neural network to it.\n",
    "- Use a cloud base experiment tracking framework such as weights and biases\n",
    "- Research potential architecture ideas for this problem. Try Lenet-10 for example. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_433_Tune_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
