{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Train Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Apply regularization techniques to your model. \n",
    "\n",
    "*Don't forgot to switch to GPU on Colab!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJ2b3wk62Ud"
   },
   "source": [
    "## Regularization\n",
    "\n",
    "Using your best performing model from the previous module, apply each of the following regularization strategies: \n",
    "* Early Stopping\n",
    "* Dropout\n",
    "* Weight Decay\n",
    "* Weight Constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USXjs7Hk71Hy"
   },
   "outputs": [],
   "source": [
    "# Your Code Starts Here\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Starts Here\n",
    "def load_quickdraw10(path):\n",
    "  data = np.load(path)\n",
    "  X = data['arr_0']\n",
    "  y = data['arr_1']\n",
    "  X, y = shuffle(X, y)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                      random_state=42)\n",
    "  \n",
    "  return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_quickdraw10('../quickdraw10.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    opt = Adam(learning_rate=.001)\n",
    "    model.add(Dense(32, input_dim=784, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "   1/2500 [..............................] - ETA: 0s - loss: 88.9758 - accuracy: 0.1562WARNING:tensorflow:From C:\\Users\\timro\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/2500 [..............................] - ETA: 1:02 - loss: 78.5327 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0481s). Check your callbacks.\n",
      "2500/2500 [==============================] - 2s 616us/step - loss: 2.1097 - accuracy: 0.4431 - val_loss: 1.2942 - val_accuracy: 0.5418\n",
      "Epoch 2/99\n",
      "2500/2500 [==============================] - 1s 555us/step - loss: 1.2165 - accuracy: 0.5806 - val_loss: 1.1690 - val_accuracy: 0.6154\n",
      "Epoch 3/99\n",
      "2500/2500 [==============================] - 1s 564us/step - loss: 1.1136 - accuracy: 0.6300 - val_loss: 1.0940 - val_accuracy: 0.6544\n",
      "Epoch 4/99\n",
      "2500/2500 [==============================] - 1s 577us/step - loss: 1.0500 - accuracy: 0.6647 - val_loss: 1.0892 - val_accuracy: 0.6430\n",
      "Epoch 5/99\n",
      "2500/2500 [==============================] - 1s 594us/step - loss: 1.0048 - accuracy: 0.6861 - val_loss: 1.0192 - val_accuracy: 0.6826\n",
      "Epoch 6/99\n",
      "2500/2500 [==============================] - 1s 585us/step - loss: 0.9703 - accuracy: 0.6983 - val_loss: 0.9966 - val_accuracy: 0.6978\n",
      "Epoch 7/99\n",
      "2500/2500 [==============================] - 1s 577us/step - loss: 0.9385 - accuracy: 0.7094 - val_loss: 0.9978 - val_accuracy: 0.6937\n",
      "Epoch 8/99\n",
      "2500/2500 [==============================] - 1s 589us/step - loss: 0.9073 - accuracy: 0.7188 - val_loss: 0.9226 - val_accuracy: 0.7166\n",
      "Epoch 9/99\n",
      "2500/2500 [==============================] - 1s 588us/step - loss: 0.8729 - accuracy: 0.7269 - val_loss: 0.9165 - val_accuracy: 0.7111\n",
      "Epoch 10/99\n",
      "2500/2500 [==============================] - 1s 587us/step - loss: 0.8446 - accuracy: 0.7400 - val_loss: 0.8699 - val_accuracy: 0.7339\n",
      "Epoch 11/99\n",
      "2500/2500 [==============================] - 1s 548us/step - loss: 0.8141 - accuracy: 0.7502 - val_loss: 0.8335 - val_accuracy: 0.7515\n",
      "Epoch 12/99\n",
      "2500/2500 [==============================] - 1s 553us/step - loss: 0.7995 - accuracy: 0.7601 - val_loss: 0.8279 - val_accuracy: 0.7548\n",
      "Epoch 13/99\n",
      "2500/2500 [==============================] - 1s 550us/step - loss: 0.7808 - accuracy: 0.7655 - val_loss: 0.8169 - val_accuracy: 0.7570\n",
      "Epoch 14/99\n",
      "2500/2500 [==============================] - 1s 549us/step - loss: 0.7771 - accuracy: 0.7655 - val_loss: 0.8196 - val_accuracy: 0.7578\n",
      "Epoch 15/99\n",
      "2500/2500 [==============================] - 1s 557us/step - loss: 0.7550 - accuracy: 0.7723 - val_loss: 0.8182 - val_accuracy: 0.7559\n",
      "Epoch 16/99\n",
      "2500/2500 [==============================] - 1s 546us/step - loss: 0.7443 - accuracy: 0.7750 - val_loss: 0.7932 - val_accuracy: 0.7670\n",
      "Epoch 17/99\n",
      "2500/2500 [==============================] - 1s 542us/step - loss: 0.7341 - accuracy: 0.7775 - val_loss: 0.7913 - val_accuracy: 0.7665\n",
      "Epoch 18/99\n",
      "2500/2500 [==============================] - 1s 546us/step - loss: 0.7253 - accuracy: 0.7804 - val_loss: 0.7822 - val_accuracy: 0.7770\n",
      "Epoch 19/99\n",
      "2500/2500 [==============================] - 1s 553us/step - loss: 0.7184 - accuracy: 0.7848 - val_loss: 0.7661 - val_accuracy: 0.7739\n",
      "Epoch 20/99\n",
      "2500/2500 [==============================] - 1s 551us/step - loss: 0.7082 - accuracy: 0.7891 - val_loss: 0.7522 - val_accuracy: 0.7766\n",
      "Epoch 21/99\n",
      "2500/2500 [==============================] - 1s 547us/step - loss: 0.6941 - accuracy: 0.7941 - val_loss: 0.7603 - val_accuracy: 0.7836\n",
      "Epoch 22/99\n",
      "2500/2500 [==============================] - 1s 540us/step - loss: 0.6879 - accuracy: 0.7947 - val_loss: 0.7373 - val_accuracy: 0.7885\n",
      "Epoch 23/99\n",
      "2500/2500 [==============================] - 1s 548us/step - loss: 0.6754 - accuracy: 0.7982 - val_loss: 0.7289 - val_accuracy: 0.7883\n",
      "Epoch 24/99\n",
      "2500/2500 [==============================] - 1s 543us/step - loss: 0.6705 - accuracy: 0.8022 - val_loss: 0.7298 - val_accuracy: 0.7916\n",
      "Epoch 25/99\n",
      "2500/2500 [==============================] - 1s 549us/step - loss: 0.6686 - accuracy: 0.8029 - val_loss: 0.7378 - val_accuracy: 0.7886\n",
      "Epoch 26/99\n",
      "2500/2500 [==============================] - 1s 555us/step - loss: 0.6618 - accuracy: 0.8029 - val_loss: 0.7200 - val_accuracy: 0.7929\n",
      "Epoch 27/99\n",
      "2500/2500 [==============================] - 1s 551us/step - loss: 0.6611 - accuracy: 0.8060 - val_loss: 0.7303 - val_accuracy: 0.7936\n",
      "Epoch 28/99\n",
      "2500/2500 [==============================] - 1s 554us/step - loss: 0.6606 - accuracy: 0.8051 - val_loss: 0.7368 - val_accuracy: 0.7885\n",
      "Epoch 29/99\n",
      "2500/2500 [==============================] - 1s 552us/step - loss: 0.6606 - accuracy: 0.8053 - val_loss: 0.7444 - val_accuracy: 0.7841\n",
      "Epoch 30/99\n",
      "2500/2500 [==============================] - 1s 541us/step - loss: 0.6567 - accuracy: 0.8062 - val_loss: 0.7605 - val_accuracy: 0.7883\n",
      "Epoch 31/99\n",
      "2500/2500 [==============================] - 1s 543us/step - loss: 0.6530 - accuracy: 0.8069 - val_loss: 0.7491 - val_accuracy: 0.7885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c921380d60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5)\n",
    "\n",
    "model= create_model()\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "wc = MaxNorm(max_value=2)\n",
    "cpoint = tf.keras.callbacks.ModelCheckpoint(\"weights_best.h5\",\n",
    "                                            verbose=1,\n",
    "                                            save_weights_only=True)\n",
    "def create_model_dropout():\n",
    "    # create model\n",
    "    opt = Adam(learning_rate=.001)\n",
    "    model = Sequential([\n",
    "    Dense(32,input_dim =784, kernel_constraint=wc),\n",
    "    ReLU(negative_slope=.01),\n",
    "    Dense(32, kernel_constraint=wc),\n",
    "    ReLU(negative_slope=.01),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "2416/2500 [===========================>..] - ETA: 0s - loss: 1.7976 - accuracy: 0.6243\n",
      "Epoch 00001: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 673us/step - loss: 1.7682 - accuracy: 0.6278 - val_loss: 0.8923 - val_accuracy: 0.7362\n",
      "Epoch 2/99\n",
      "2410/2500 [===========================>..] - ETA: 0s - loss: 0.8224 - accuracy: 0.7591\n",
      "Epoch 00002: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 608us/step - loss: 0.8212 - accuracy: 0.7593 - val_loss: 0.7935 - val_accuracy: 0.7683\n",
      "Epoch 3/99\n",
      "2476/2500 [============================>.] - ETA: 0s - loss: 0.7492 - accuracy: 0.7831\n",
      "Epoch 00003: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 1s 596us/step - loss: 0.7502 - accuracy: 0.7828 - val_loss: 0.7191 - val_accuracy: 0.7888\n",
      "Epoch 4/99\n",
      "2411/2500 [===========================>..] - ETA: 0s - loss: 0.7041 - accuracy: 0.7943\n",
      "Epoch 00004: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 626us/step - loss: 0.7041 - accuracy: 0.7941 - val_loss: 0.7006 - val_accuracy: 0.7903\n",
      "Epoch 5/99\n",
      "2459/2500 [============================>.] - ETA: 0s - loss: 0.6647 - accuracy: 0.8030\n",
      "Epoch 00005: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 607us/step - loss: 0.6649 - accuracy: 0.8032 - val_loss: 0.7127 - val_accuracy: 0.7875\n",
      "Epoch 6/99\n",
      "2493/2500 [============================>.] - ETA: 0s - loss: 0.6427 - accuracy: 0.8110\n",
      "Epoch 00006: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 613us/step - loss: 0.6426 - accuracy: 0.8110 - val_loss: 0.6603 - val_accuracy: 0.8096\n",
      "Epoch 7/99\n",
      "2495/2500 [============================>.] - ETA: 0s - loss: 0.6220 - accuracy: 0.8175\n",
      "Epoch 00007: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 620us/step - loss: 0.6220 - accuracy: 0.8175 - val_loss: 0.6580 - val_accuracy: 0.8091\n",
      "Epoch 8/99\n",
      "2415/2500 [===========================>..] - ETA: 0s - loss: 0.6010 - accuracy: 0.8229\n",
      "Epoch 00008: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 615us/step - loss: 0.6038 - accuracy: 0.8223 - val_loss: 0.6393 - val_accuracy: 0.8146\n",
      "Epoch 9/99\n",
      "2453/2500 [============================>.] - ETA: 0s - loss: 0.5929 - accuracy: 0.8255\n",
      "Epoch 00009: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 1s 599us/step - loss: 0.5934 - accuracy: 0.8253 - val_loss: 0.6229 - val_accuracy: 0.8169\n",
      "Epoch 10/99\n",
      "2481/2500 [============================>.] - ETA: 0s - loss: 0.5798 - accuracy: 0.8283\n",
      "Epoch 00010: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 620us/step - loss: 0.5794 - accuracy: 0.8283 - val_loss: 0.6071 - val_accuracy: 0.8273\n",
      "Epoch 11/99\n",
      "2461/2500 [============================>.] - ETA: 0s - loss: 0.5748 - accuracy: 0.8302\n",
      "Epoch 00011: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 1s 595us/step - loss: 0.5745 - accuracy: 0.8301 - val_loss: 0.6391 - val_accuracy: 0.8194\n",
      "Epoch 12/99\n",
      "2467/2500 [============================>.] - ETA: 0s - loss: 0.5697 - accuracy: 0.8319\n",
      "Epoch 00012: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 1s 597us/step - loss: 0.5698 - accuracy: 0.8319 - val_loss: 0.6419 - val_accuracy: 0.8225\n",
      "Epoch 13/99\n",
      "2469/2500 [============================>.] - ETA: 0s - loss: 0.5613 - accuracy: 0.8340\n",
      "Epoch 00013: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 1s 595us/step - loss: 0.5615 - accuracy: 0.8338 - val_loss: 0.6032 - val_accuracy: 0.8282\n",
      "Epoch 14/99\n",
      "2454/2500 [============================>.] - ETA: 0s - loss: 0.5541 - accuracy: 0.8360\n",
      "Epoch 00014: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 602us/step - loss: 0.5542 - accuracy: 0.8361 - val_loss: 0.6092 - val_accuracy: 0.8250\n",
      "Epoch 15/99\n",
      "2475/2500 [============================>.] - ETA: 0s - loss: 0.5514 - accuracy: 0.8370\n",
      "Epoch 00015: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 613us/step - loss: 0.5513 - accuracy: 0.8370 - val_loss: 0.5927 - val_accuracy: 0.8274\n",
      "Epoch 16/99\n",
      "2401/2500 [===========================>..] - ETA: 0s - loss: 0.5509 - accuracy: 0.8371\n",
      "Epoch 00016: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 615us/step - loss: 0.5517 - accuracy: 0.8368 - val_loss: 0.6147 - val_accuracy: 0.8283\n",
      "Epoch 17/99\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 0.8388\n",
      "Epoch 00017: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 610us/step - loss: 0.5467 - accuracy: 0.8388 - val_loss: 0.5995 - val_accuracy: 0.8273\n",
      "Epoch 18/99\n",
      "2477/2500 [============================>.] - ETA: 0s - loss: 0.5367 - accuracy: 0.8396\n",
      "Epoch 00018: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 613us/step - loss: 0.5367 - accuracy: 0.8398 - val_loss: 0.5830 - val_accuracy: 0.8299\n",
      "Epoch 19/99\n",
      "2475/2500 [============================>.] - ETA: 0s - loss: 0.5404 - accuracy: 0.8404\n",
      "Epoch 00019: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 1s 593us/step - loss: 0.5401 - accuracy: 0.8405 - val_loss: 0.5994 - val_accuracy: 0.8275\n",
      "Epoch 20/99\n",
      "2435/2500 [============================>.] - ETA: 0s - loss: 0.5337 - accuracy: 0.8413\n",
      "Epoch 00020: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 606us/step - loss: 0.5342 - accuracy: 0.8413 - val_loss: 0.5811 - val_accuracy: 0.8310\n",
      "Epoch 21/99\n",
      "2456/2500 [============================>.] - ETA: 0s - loss: 0.5336 - accuracy: 0.8419\n",
      "Epoch 00021: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 624us/step - loss: 0.5356 - accuracy: 0.8417 - val_loss: 0.6015 - val_accuracy: 0.8251\n",
      "Epoch 22/99\n",
      "2407/2500 [===========================>..] - ETA: 0s - loss: 0.5339 - accuracy: 0.8423\n",
      "Epoch 00022: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 610us/step - loss: 0.5334 - accuracy: 0.8424 - val_loss: 0.6006 - val_accuracy: 0.8294\n",
      "Epoch 23/99\n",
      "2403/2500 [===========================>..] - ETA: 0s - loss: 0.5292 - accuracy: 0.8428\n",
      "Epoch 00023: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 612us/step - loss: 0.5310 - accuracy: 0.8422 - val_loss: 0.6088 - val_accuracy: 0.8253\n",
      "Epoch 24/99\n",
      "2455/2500 [============================>.] - ETA: 0s - loss: 0.5290 - accuracy: 0.8431\n",
      "Epoch 00024: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 619us/step - loss: 0.5292 - accuracy: 0.8431 - val_loss: 0.5631 - val_accuracy: 0.8349\n",
      "Epoch 25/99\n",
      "2452/2500 [============================>.] - ETA: 0s - loss: 0.5268 - accuracy: 0.8440\n",
      "Epoch 00025: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 605us/step - loss: 0.5264 - accuracy: 0.8440 - val_loss: 0.5934 - val_accuracy: 0.8273\n",
      "Epoch 26/99\n",
      "2436/2500 [============================>.] - ETA: 0s - loss: 0.5244 - accuracy: 0.8452\n",
      "Epoch 00026: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 606us/step - loss: 0.5249 - accuracy: 0.8450 - val_loss: 0.5726 - val_accuracy: 0.8360\n",
      "Epoch 27/99\n",
      "2443/2500 [============================>.] - ETA: 0s - loss: 0.5226 - accuracy: 0.8444\n",
      "Epoch 00027: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 624us/step - loss: 0.5229 - accuracy: 0.8444 - val_loss: 0.5843 - val_accuracy: 0.8287\n",
      "Epoch 28/99\n",
      "2491/2500 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.8448\n",
      "Epoch 00028: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 610us/step - loss: 0.5243 - accuracy: 0.8447 - val_loss: 0.6333 - val_accuracy: 0.8180\n",
      "Epoch 29/99\n",
      "2467/2500 [============================>.] - ETA: 0s - loss: 0.5210 - accuracy: 0.8448\n",
      "Epoch 00029: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 2s 603us/step - loss: 0.5216 - accuracy: 0.8445 - val_loss: 0.5865 - val_accuracy: 0.8370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c9286f5c10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= create_model_dropout()\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[stop, cpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pScpa3nRRxCN"
   },
   "source": [
    "## Deploy\n",
    "\n",
    "Save your model's weights using the Checkpoint function. Try reloading the model and making inference on your validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cqpHQt_SIbW"
   },
   "outputs": [],
   "source": [
    "# Your Code Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12428), started 0:01:55 ago. (Use '!kill 12428' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ba9afbd19fc55e2b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ba9afbd19fc55e2b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-9210fe420116>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model_dropout()\n",
    "\n",
    "model.load_weights('weights_best.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 350us/step - loss: 0.5865 - accuracy: 0.8370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5865088105201721, 0.8369500041007996]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKbr1gRg9BXs"
   },
   "source": [
    "### Stretch Goals\n",
    "- Mount your Google Drive to Colab to persist your model checkpoint files. \n",
    "- Research L2 normalization (weight decay)\n",
    "- Write a custom callback function to stop training after you reach .88 validation accuracy. \n",
    "- Select a new dataset and apply a neural network to it.\n",
    "- Research TensorFlow Serving\n",
    "- Play [QuickDraw](https://quickdraw.withgoogle.com/data)\n",
    "- Create a static webpage using TensorFlow.js to serve a model. Check out [Teachable Machine Learning](https://teachablemachine.withgoogle.com/) for ideas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('val_accuracy') > .88):   \n",
    "            self.model.stop_training = True"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_434_Deploy_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
